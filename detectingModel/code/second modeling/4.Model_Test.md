# 학습된 model test

* 학습된 모델을 이미지에 적용하여 마스크를 착용한 ROI 영역을 찾고자 했다.
* window sliding 을 통해 window size 를 늘려가며 모델을 적용하여 ROI 영역을 추출해 보았다.
* 하지만 window size 에 따른 window sliding 을 위해 3중 loop 문이 이용되었고, 따라서 이미지당 초단위의 처리 시간이 소요 되었다.
  * 실시간 영상에 적용하기 어려웠다.
* 그리고 아직 부족한 data로 인해 overfitting 이 이루어져 마스크를 착용한 얼굴 부분 외의 바탕화면을 ROI 영역으로 찾아지는 경우, 또 window size 의 크기에 맞지 않는 부분까지 ROI 영역으로 찾아지는 경우가 발생하였다.



## code

```python
# get hog feature of mask images
import cv2
import glob
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.externals import joblib
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from skimage import exposure
from skimage import feature
from imutils import paths
import argparse
import imutils



def get_hog(size):
    winSize = (size, size)
    blockSize = (16,16)
    blockStride = (8,8)
    cellSize = (8,8)
    nbins = 9
    derivAperture = 1
    winSigma = -1.
    histogramNormType = 0
    L2HysThreshold = 0.2
    gammaCorrection = 1
    nlevels = 64
    signedGradients = True

    hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins,derivAperture,winSigma,histogramNormType,L2HysThreshold,gammaCorrection,nlevels, signedGradients)
    return hog

def hog_feature(img, size):
    hog = get_hog(size)
#     img = cv2.imread(img_path, 0)
#     img = cv2.resize(img, dsize=(size, size), interpolation=cv2.INTER_AREA)
    hog_feature = hog.compute(img)
    hog_feature = np.array(hog_feature).flatten().tolist()
#     hog_feature = np.array(hog_feature).flatten()
    return hog_feature

def detect_Mask(img, sliding_pixel, window_pixel, size, svm):
    idx = 0
    hog = get_hog(size)
    
    mask_locations = []
    TOP = 0
    RIGHT = img.shape[1]
    BOTTOM = img.shape[0]
    LEFT = 0
    
    top = TOP
    right = int(RIGHT * 12 / 100)
    bottom = int(BOTTOM * 25 / 100)
    left = LEFT
    while(True):
        if right >= RIGHT or bottom >= BOTTOM:
            break
        t = top
        r = right
        b = bottom
        l = left
        while(True):
            if b >= BOTTOM:
                break
            while(True):
                if r >= RIGHT:
                    break
                trim_img = img[t:b, l:r]
                trim_img = cv2.resize(trim_img, dsize=(size, size), interpolation=cv2.INTER_AREA)
                hog_feature = hog.compute(trim_img)
                hog_feature = np.array(hog_feature).flatten().tolist()
                y_pred = svm.predict([hog_feature])
                if y_pred[0] == 1:
                    mask_locations.append([t, r, b, l])
                    print('aaa')
                img2 = img.copy()
                cv2.rectangle(img2, (l, t), (r,b), (0,0,255), 2)
                cv2.imwrite("ee/" + str(idx) + ".png", img2)
                idx += 1
#                 cv2.rectangle(img2, (l, t), (r,b), (0,0,255), 3)
#                 cv2.imshow('img2', img2)
#                 cv2.waitKey(1)
#                 cv2.destroyAllWindows()
                l += sliding_pixel
                r += sliding_pixel
            l = left
            r = right
            t += sliding_pixel
            b += sliding_pixel
        right += window_pixel
        bottom += window_pixel
    return mask_locations
```

* main

```python
img_path = 'testv/images/testv6/220.jpg'
svm = joblib.load('lib/maskSVM-1.pkl')
sliding_pixel = 20
window_pixel = 20
size = 80
                             

ori = cv2.imread(img_path)
filename = 'img/preprocessed4/data/'
img = cv2.imread(img_path, 0)

# t = int(img.shape[0]*20/100)
# r = int(img.shape[1]*80/100)
# b = int(img.shape[0]*80/100)
# l = int(img.shape[1]*20/100)
# img = trim_img = img[t:b, l:r]

mask_locations = detect_Mask(img, sliding_pixel, window_pixel, size, svm)
# mask_locations = detect_Mask2(ori, img, sliding_pixel, window_pixel, size, svm, filename, 2438)
for mask_location in mask_locations:
    top, right, bottom, left = mask_location
    # 얼굴 부분만 따로 저장
    trim_img = img[top:bottom, left:right]
#     print(trim_img.shape)
#     cv2.imwrite("out5.jpg", trim_img)
    cv2.rectangle(img, (left, top), (right,bottom), (0,0,255), 2)
print("end")
cv2.imwrite("img.jpg", img)
cv2.imshow('img', img)
cv2.waitKey()
cv2.destroyAllWindows()
```





# 문제 해결

* 프로그램 최적화가 이루어 지지 않아 실시간 영상에 적용되지 않는 문제점 해결 방법
  * model 을 적용하는 부분을 이미지 전체가 아닌 특정 영역으로 제한했다.
* overfitting 문제 해결 방법
  * 추가적인 data 수집으로 model 의 성능을 개선시키고자 했다.
* 위의 두 방법을 적용하여 웹캠에 연동하여 실시간 서비스 프로그램을 작성해 보았다.

## code

* header

```python
import cv2
import numpy as np
import math
import face_recognition
from sklearn.externals import joblib
```

* 전처리 및 웹캠과 연동하여 판별하는 코드

```python
def get_hog(size):
    winSize = (size, size)
    blockSize = (16,16)
    blockStride = (8,8)
    cellSize = (8,8)
    nbins = 9
    derivAperture = 1
    winSigma = -1.
    histogramNormType = 0
    L2HysThreshold = 0.2
    gammaCorrection = 1
    nlevels = 64
    signedGradients = True

    hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins,derivAperture,winSigma,histogramNormType,L2HysThreshold,gammaCorrection,nlevels, signedGradients)
    return hog

def access_control(svm, size):
    cap = cv2.VideoCapture(0)
    hog = get_hog(size)
    font = cv2.FONT_HERSHEY_SIMPLEX
    if cap.isOpened() == False:
        print('Camera is closed!')
        
    #재생할 파일의 넓이 얻기
    width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)
    #재생할 파일의 높이 얻기
    height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
    #재생할 파일의 프레임 레이트 얻기
    #fps = cap.get(cv2.CAP_PROP_FPS)
    #재생할 파일의 프레임 레이트 얻기
    #counts = cap.get(cv2.CAP_PROP_FRAME_COUNT)
    
    if width > height: radius = int(height * 21 / 100)
    else : radius = int(width * 21 / 100)
    
#     side = int(math.sqrt(math.pow(radius, 2) / 2))
    side = int(radius*90/100)
    centerX = int(width/2)
    centerY = int(height/2)
    print(width, height)
    
    while cap.isOpened():
        ret, frame = cap.read()
        # 1은 좌우반전, 0은 상하 반전
        frame = cv2.flip(frame, 1)
        
        trim_img = frame[centerY-side:centerY+side, centerX-side:centerX+side]
        face_locations = face_recognition.face_locations(trim_img)
        
        if len(face_locations) > 0:
#             cv2.rectangle(frame, (centerX-side, centerY-side), (centerX+side, centerY+side), (0,0,255), 2)
            cv2.putText(frame, 'NO Mask', (centerX-radius, centerY-radius), font, 0.9, (0, 0, 255), 2)
            cv2.circle(frame, (centerX, centerY), radius, (0, 0, 255), 2)
        else:
            trim_img = cv2.resize(trim_img, dsize=(size, size), interpolation=cv2.INTER_AREA)
            hog_feature = hog.compute(trim_img)
            hog_feature = np.array(hog_feature).flatten().tolist()
            y_pred = svm.predict([hog_feature])
            if y_pred[0] == 1:
                cv2.putText(frame, 'Mask On', (centerX-radius, centerY-radius), font, 0.9, (255, 0, 0), 2)
                cv2.circle(frame, (centerX, centerY), radius, (255, 0, 0), 2)
            else:
                cv2.putText(frame, 'NO Face', (centerX-radius, centerY-radius), font, 0.9, (0, 255, 255), 2)
                cv2.circle(frame, (centerX, centerY), radius, (0, 255, 255), 2)
#             cv2.rectangle(frame, (centerX-side, centerY-side), (centerX+side, centerY+side), (0,255,255), 2)
#         cv2.circle(frame, (centerX, centerY), radius, (0, 255, 255), 2)
#         cv2.rectangle(frame, (centerX-side, centerY-side), (centerX+side, centerY+side), (0,255,255), 2)
        cv2.imshow('Frame', frame)
     
        # ESC 누르면 27이 입력으로 들어온다.
        if cv2.waitKey(1) == 27:
            break
 
    cap.release()
    cv2.destroyAllWindows()
```

* main

```python
svm = joblib.load('lib/maskSVM-1.pkl')
access_control(svm, 80)
```

